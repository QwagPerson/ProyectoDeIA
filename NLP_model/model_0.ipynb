{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proeycto de IA - ChatBox\n",
        "\n",
        "Departamento de Ciencias de la Computación, Universidad de Chile.\n",
        "\n",
        "CC6409: Taller de Desarrollo de Poryectod e IA - Otoño 2023\n",
        "\n",
        "**Integrantes:**\n",
        "- Garrido Martín\n",
        "- Gómez Nahuel\n",
        "- Santelices Gustavo\n"
      ],
      "metadata": {
        "id": "RrDk4gjfu6HL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "SugtK4Qlu19U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score, classification_report\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import re\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XJbIlDWjqXHA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data"
      ],
      "metadata": {
        "id": "47_Qf8Fiu3y7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "J0NrlV_7ppMu"
      },
      "outputs": [],
      "source": [
        "# handmade\n",
        "hand_nawel_0 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/asistire_nawel.csv\", sep = ';')\n",
        "hand_nawel_1 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/no_asistire_nawel.csv\", sep = ';')\n",
        "hand_nawel_2 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/reagendar_nawel.csv\", sep = ';')\n",
        "hand_nawel_3 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/pedir_nawel.csv\", sep = ';')\n",
        "\n",
        "hand_tavo_0 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/asistire_tavo.csv\", sep = ',')\n",
        "hand_tavo_1 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/no_asistire_tavo.csv\", sep = ',')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT\n",
        "gpt_nawel_0 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/GPT_generated/asistire_nawel.csv\", sep = ';')\n",
        "gpt_nawel_1 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/GPT_generated/no_asistire_nawel.csv\", sep = ';')\n",
        "gpt_nawel_2 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/GPT_generated/reagendar_nawel.csv\", sep = ';')\n",
        "gpt_nawel_3 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/GPT_generated/pedir_nawel.csv\", sep = ';')\n"
      ],
      "metadata": {
        "id": "sRwvvqnJqfKQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ = pd.concat([hand_nawel_0, hand_nawel_1, hand_nawel_2, hand_nawel_3,\n",
        "                 gpt_nawel_0, gpt_nawel_1, gpt_nawel_2, gpt_nawel_3,\n",
        "                 hand_tavo_0, hand_tavo_1])\n",
        "\n",
        "df_.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piVtRE1KtSBs",
        "outputId": "f2cc31f3-1b75-44d4-923d-43bb46b5027d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class    230\n",
              "text     230\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbkIOlhkuNP8",
        "outputId": "0cf636c5-f58d-41db-b89d-e7c778795b4f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    79\n",
              "1    78\n",
              "2    37\n",
              "3    36\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Features"
      ],
      "metadata": {
        "id": "0a2GPoPe1fpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PreProccesingTransformer(BaseEstimator, TransformerMixin):\n",
        "    def preprocess(self,sentence):\n",
        "      # Deleting all except: exclamation/question signs and accents\n",
        "      new_word = re.sub(r\"[^a-zA-ZáéíóúÁÉÍÓÚñÑ¡!¿?\\s]\", '', sentence)\n",
        "      # Deleting double blank spaces\n",
        "      new_sentence = new_word.replace('  ',' ').replace('\\n','').strip()\n",
        "      return new_sentence\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        values = []\n",
        "        for tweet in X:\n",
        "            values.append(self.preprocess(tweet))\n",
        "\n",
        "        return(np.array(values))\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self"
      ],
      "metadata": {
        "id": "gxQn-gB91jds"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline"
      ],
      "metadata": {
        "id": "6LJM2N-Uvx0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Pipeline"
      ],
      "metadata": {
        "id": "dewh_gkEyZNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run(dataset, pipeline):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        dataset['text'],\n",
        "        dataset['class'],\n",
        "        shuffle=True,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=dataset['class']\n",
        "    )\n",
        "\n",
        "    print(f\"# Len Training Data: {len(X_train)}\")\n",
        "    print(f\"# Len Testing Data: {len(X_test)}\")\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    predicted_labels = pipeline.predict(X_test)\n",
        "\n",
        "    print(classification_report(y_test, predicted_labels))\n",
        "\n",
        "\n",
        "    return pipeline, X_train, X_test, y_train, y_test, predicted_labels\n"
      ],
      "metadata": {
        "id": "GGE3LfHRysWI"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Pipelines"
      ],
      "metadata": {
        "id": "wIMBgRmCyd6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple Pipeline only BOW\n",
        "\n",
        "def get_experiment_0_pipeline():\n",
        "\n",
        "    return Pipeline(\n",
        "        [\n",
        "            (\n",
        "                \"features\",\n",
        "                FeatureUnion(\n",
        "                    [\n",
        "                        (\"bow\", CountVectorizer()),\n",
        "                    ]\n",
        "                ),\n",
        "            ),\n",
        "            (\"clf\", MultinomialNB()),\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "RoiPLpB6wNgx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple Pipeline only Preprocessing + BOW\n",
        "\n",
        "def get_experiment_1_pipeline():\n",
        "\n",
        "    return Pipeline(\n",
        "        [\n",
        "            (\"preprocessing\", PreProccesingTransformer()),\n",
        "            (\n",
        "                \"features\",\n",
        "                FeatureUnion(\n",
        "                    [\n",
        "                        (\"bow\", CountVectorizer())\n",
        "                    ]\n",
        "                ),\n",
        "            ),\n",
        "            (\"clf\", MultinomialNB()),\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "tqZbmwfz2UTM"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementación del modelo"
      ],
      "metadata": {
        "id": "f7cZ4DHxxQMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Pipeline Test\n",
        "pipeline0 = get_experiment_0_pipeline()\n",
        "\n",
        "_ = run(df_, pipeline0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2Jy6hTjyG5A",
        "outputId": "f2edf873-d3e3-420f-daa2-62a8a2161496"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Len Training Data: 184\n",
            "# Len Testing Data: 46\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88        16\n",
            "           1       0.78      0.88      0.82        16\n",
            "           2       1.00      0.57      0.73         7\n",
            "           3       0.88      1.00      0.93         7\n",
            "\n",
            "    accuracy                           0.85        46\n",
            "   macro avg       0.88      0.83      0.84        46\n",
            "weighted avg       0.86      0.85      0.84        46\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Pipeline Test (+ preprocessing)\n",
        "pipeline1 = get_experiment_1_pipeline()\n",
        "\n",
        "_ = run(df_, pipeline1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnQh_0k42teE",
        "outputId": "eedce83f-977c-4627-a216-04b402f22965"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Len Training Data: 184\n",
            "# Len Testing Data: 46\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88        16\n",
            "           1       0.78      0.88      0.82        16\n",
            "           2       1.00      0.57      0.73         7\n",
            "           3       0.88      1.00      0.93         7\n",
            "\n",
            "    accuracy                           0.85        46\n",
            "   macro avg       0.88      0.83      0.84        46\n",
            "weighted avg       0.86      0.85      0.84        46\n",
            "\n"
          ]
        }
      ]
    }
  ]
}