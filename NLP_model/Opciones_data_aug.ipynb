{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e246d0b-48dd-4979-b143-1ac246ab2486",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbkIOlhkuNP8",
    "outputId": "8234e091-add4-4988-fb00-a280e82d1d8a"
   },
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19e8628f-7a59-4a40-9820-5235e7b76e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nahue\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "                                                                                        import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score, classification_report\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "import numpy as np\n",
    "import nlpaug.augmenter.word as naw # To synonym, see  to more info https://github.com/makcedward/nlpaug\n",
    "import nlpaug.augmenter.char as nac\n",
    "from mtranslate import translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d57e9d-40d0-4a6e-bacb-772ad7bf64da",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_nawel_0 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/GPT_generated/asistire_nawel.csv\", sep = ';')\n",
    "gpt_nawel_1 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/GPT_generated/no_asistire_nawel.csv\", sep = ';')\n",
    "gpt_nawel_2 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/GPT_generated/reagendar_nawel.csv\", sep = ';')\n",
    "gpt_nawel_3 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/GPT_generated/pedir_nawel.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ffc1ce-2cbe-43e7-af8b-73430af815f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con Bert\n",
    "aug = naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-uncased', aug_p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fc4a2de-3ded-4835-8939-6704da3b3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordnet - spa\n",
    "aug1 = naw.SynonymAug(aug_src='wordnet', lang='spa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4b1c6a-9fb0-4186-a45f-cc0136d714f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_nawel_0 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/asistire_nawel.csv\", sep = ';')\n",
    "hand_nawel_1 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/no_asistire_nawel.csv\", sep = ';')\n",
    "hand_nawel_2 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/reagendar_nawel.csv\", sep = ';')\n",
    "hand_nawel_3 = pd.read_csv(\"https://raw.githubusercontent.com/QwagPerson/ProyectoDeIA/main/Data/Handmade/pedir_nawel.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99be21f0-d3a5-4e69-a264-e3cfa797747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asistir\n",
      "Por supuesto\n",
      "Bert: ['el supuesto']\n",
      "Wordnet: ['Por supuesto'] \n",
      "\n",
      "No Asistir\n",
      "No me siento preparado para rendir la prueba, cancelame la hora\n",
      "Bert: ['yo me siento preparado para rendir la prueba, pero la hora']\n",
      "Wordnet: ['No me siento preparado para rendir la test, cancelame la hora'] \n",
      "\n",
      "Reagendar\n",
      "Puedes ayudarme a cambiar la hora para la licencia\n",
      "Bert: ['puedes ayudarme a cambiar la vida para la revolucion']\n",
      "Wordnet: ['Puedes ayudarme a cambiar la hora para la licencia'] \n",
      "\n",
      "Pedir\n",
      "Hola, ¿acá puedo pedir la hora para la licencia?\n",
      "Bert: ['hola, ¿ donde puedo pedir la hora para la virgen?']\n",
      "Wordnet: ['Hola, ¿ acá puedo pedir la esponsales para la licencia?'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Replace words with synonyms\n",
    "# Example for values in each sentences\n",
    "print('Asistir')\n",
    "print(hand_nawel_0.text[10])\n",
    "print(f'Bert: {aug.augment(hand_nawel_0.text[10])}') # show secoond row\n",
    "print(f'Wordnet: {aug1.augment(hand_nawel_0.text[10])} \\n')\n",
    "\n",
    "print('No Asistir')\n",
    "print(hand_nawel_1.text[10])\n",
    "print(f'Bert: {aug.augment(hand_nawel_1.text[10])}') # show secoond row\n",
    "print(f'Wordnet: {aug1.augment(hand_nawel_1.text[10])} \\n')\n",
    "\n",
    "print('Reagendar')\n",
    "print(hand_nawel_2.text[10])\n",
    "print(f'Bert: {aug.augment(hand_nawel_2.text[10])}') # show secoond row\n",
    "print(f'Wordnet: {aug1.augment(hand_nawel_2.text[10])} \\n')\n",
    "\n",
    "print('Pedir')\n",
    "print(hand_nawel_3.text[10])\n",
    "print(f'Bert: {aug.augment(hand_nawel_3.text[10])}') # show secoond row\n",
    "print(f'Wordnet: {aug1.augment(hand_nawel_3.text[10])} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e068c0-3ef4-45fc-83cc-1217a42eb30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_key = nac.KeyboardAug() #Keyboard Augmenter: Substitute character by keyboard distance\n",
    "aug_ins = nac.RandomCharAug(action=\"insert\") # insert randomw characters\n",
    "aug_subs = nac.RandomCharAug(action=\"substitute\") # Substitute character randomly\n",
    "aug_swp = nac.RandomCharAug(action=\"swap\") # swap randomly\n",
    "aug_del = nac.RandomCharAug(action=\"delete\") # delete randomly\n",
    "#aug_mis = naw.SpellingAug() # Substitute word by spelling mistake words dictionary (inly english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06efd899-9d7f-4344-a527-cedb26a75b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asistir\n",
      "Por supuesto\n",
      "Keyboard: ['Por Wupuexro']\n",
      "Random Insert: ['Por svutpuestho']\n",
      "Random Substitution: ['Por 3upsysto']\n",
      "Random Swap: ['Por uspuesto']\n",
      "Random delete: ['Por suuso'] \n",
      "\n",
      "No Asistir\n",
      "No me siento preparado para rendir la prueba, cancelame la hora\n",
      "Keyboard: ['No me siento prepArxdk pz5a rendir la peuebQ, sancw/ame la hora']\n",
      "Random Insert: ['No me siento Tpr(eparad@o poar(a OrenXdir la pruOebBa, cancelame la hora']\n",
      "Random Substitution: ['No me siento pre$araqm para r7nd6r la pmuoba, cancelame la borU']\n",
      "Random Swap: ['No me siento preparado para rendir la rpueab, accenlame la ohar']\n",
      "Random delete: ['No me siento reprdo para reni la ruba, canlae la hora']  \n",
      "\n",
      "Reagendar\n",
      "Puedes ayudarme a cambiar la hora para la licencia\n",
      "Keyboard: ['LuedeA aHudaGmS a caNniWr la hora para la licencia']\n",
      "Random Insert: ['Puhesdes ayudarme a ccaHmb%iar la hOoxra para la licencia']\n",
      "Random Substitution: ['#uede0 ayudarme a cambiar la hOr5 Q3ra la licencia']\n",
      "Random Swap: ['Upedse ayudarme a cambiar la hrao apar la licencia']\n",
      "Random delete: ['Puedes yudrm a ambi la oa para la licencia']  \n",
      "\n",
      "Pedir\n",
      "Hola, ¿acá puedo pedir la hora para la licencia?\n",
      "Keyboard: ['Hola, ¿ acá puedo pSd8r la hotw pzFa la ;iDencua?']\n",
      "Random Insert: ['Hola, ¿ acá puHeUdo ped4i&r la hora 2pasra la licJe+nci!a?']\n",
      "Random Substitution: ['H_lf, ¿ acá gjedo S*dir la Oorj para la licencia?']\n",
      "Random Swap: ['Hlao, ¿ acá puedo pedir la hora para la ilcenaci?']\n",
      "Random delete: ['Hl, ¿ acá puedo pei la hora aa la lcenc?']  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. add noise\n",
    "\n",
    "# Example for values in each sentences\n",
    "\n",
    "print('Asistir')\n",
    "print(hand_nawel_0.text[10])\n",
    "print(f'Keyboard: {aug_key.augment(hand_nawel_0.text[10])}') # show secoond row\n",
    "print(f'Random Insert: {aug_ins.augment(hand_nawel_0.text[10])}') # show secoond row\n",
    "print(f'Random Substitution: {aug_subs.augment(hand_nawel_0.text[10])}') # show secoond row\n",
    "print(f'Random Swap: {aug_swp.augment(hand_nawel_0.text[10])}') # show secoond row\n",
    "print(f'Random delete: {aug_del.augment(hand_nawel_0.text[10])} \\n') # show secoond row\n",
    "\n",
    "print('No Asistir')\n",
    "print(hand_nawel_1.text[10])\n",
    "print(f'Keyboard: {aug_key.augment(hand_nawel_1.text[10])}') # show secoond row\n",
    "print(f'Random Insert: {aug_ins.augment(hand_nawel_1.text[10])}') # show secoond row\n",
    "print(f'Random Substitution: {aug_subs.augment(hand_nawel_1.text[10])}') # show secoond row\n",
    "print(f'Random Swap: {aug_swp.augment(hand_nawel_1.text[10])}') # show secoond row\n",
    "print(f'Random delete: {aug_del.augment(hand_nawel_1.text[10])}  \\n') # show secoond row\n",
    "\n",
    "print('Reagendar')\n",
    "print(hand_nawel_2.text[10])\n",
    "print(f'Keyboard: {aug_key.augment(hand_nawel_2.text[10])}') # show secoond row\n",
    "print(f'Random Insert: {aug_ins.augment(hand_nawel_2.text[10])}') # show secoond row\n",
    "print(f'Random Substitution: {aug_subs.augment(hand_nawel_2.text[10])}') # show secoond row\n",
    "print(f'Random Swap: {aug_swp.augment(hand_nawel_2.text[10])}') # show secoond row\n",
    "print(f'Random delete: {aug_del.augment(hand_nawel_2.text[10])}  \\n') # show secoond row\n",
    "\n",
    "print('Pedir')\n",
    "print(hand_nawel_3.text[10])\n",
    "print(f'Keyboard: {aug_key.augment(hand_nawel_3.text[10])}') # show secoond row\n",
    "print(f'Random Insert: {aug_ins.augment(hand_nawel_3.text[10])}') # show secoond row\n",
    "print(f'Random Substitution: {aug_subs.augment(hand_nawel_3.text[10])}') # show secoond row\n",
    "print(f'Random Swap: {aug_swp.augment(hand_nawel_3.text[10])}') # show secoond row\n",
    "print(f'Random delete: {aug_del.augment(hand_nawel_3.text[10])}  \\n') # show secoond row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1692d799-6a9d-4abf-89ac-eef803960c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra : Translate Ideas\n",
    "def sp_to_en(data):\n",
    "    augmented_data = []\n",
    "    for sentence in data:\n",
    "        # Translate Spanish sentence to English\n",
    "        translated_sentence = translate(sentence, \"en\")\n",
    "        augmented_data.append(translated_sentence)\n",
    "\n",
    "    return augmented_data\n",
    "\n",
    "def en_to_sp(data):\n",
    "    augmented_data = []\n",
    "    for sentence in data:\n",
    "        # Translate English sentence to Spanish\n",
    "        translated_sentence = translate(sentence, \"es\")\n",
    "\n",
    "        augmented_data.append(translated_sentence)\n",
    "\n",
    "    return augmented_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efeb2e-cebb-4301-94b5-77f179ff5050",
   "metadata": {},
   "source": [
    "Other option, translate to english before the data aug and after that, translate to spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce084320-1b4c-48b6-9376-22e6ca02eb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orig: si, confirmo\n",
      "Eng: yes, I confirm\n",
      "Spa: si, lo confirmo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This idea can be used to find synonyms in english.\n",
    "original = hand_nawel_0.text.tolist()\n",
    "augmented_sentences = sp_to_en(original)\n",
    "augmented_sentences2 = en_to_sp(augmented_sentences)\n",
    "\n",
    "print(f'Orig: {original[1]}')\n",
    "print(f'Eng: {augmented_sentences[1]}')\n",
    "print(f'Spa: {augmented_sentences2[1]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b406ecfe-1fd0-4132-bb00-98b426c8d72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, I confirm my attendance', 'yes, I confirm', 'Yes, I will attend the stipulated date']\n"
     ]
    }
   ],
   "source": [
    "print(augmented_sentences[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22039c1a-4958-49fb-8fa0-168a926e5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_wordnet = naw.SynonymAug(aug_src='wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d6bcedd-0d5f-4daa-91a8-6a74d7a644d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_fb = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de', \n",
    "    to_model_name='facebook/wmt19-de-en'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f82bbd51-450c-42b6-afb6-70562e41dce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################Casos WORDNET######################\n",
      "Original: Hola, confirmo mi asistencia\n",
      "English: Hello, I confirm my attendance\n",
      "Augmented Text: Hello, I confirm my attending\n",
      "To spanish version: Hola confirmo mi asistencia \n",
      "\n",
      "Original: si, confirmo\n",
      "English: yes, I confirm\n",
      "Augmented Text: yes, I affirm\n",
      "To spanish version: si, afirmo \n",
      "\n",
      "Original: Si, asistiré a la fecha estipulada\n",
      "English: Yes, I will attend the stipulated date\n",
      "Augmented Text: Yes, Iodin testament attend the stipulated day of the month\n",
      "To spanish version: Si, Iodin testament asistir el día estipulado del mes \n",
      "\n",
      "Original: Si\n",
      "English: And\n",
      "Augmented Text: And\n",
      "To spanish version: Y \n",
      "\n",
      "Original: Ok\n",
      "English: Ok\n",
      "Augmented Text: Oklahoma\n",
      "To spanish version: Oklahoma \n",
      "\n",
      "######################Casos Facebook######################\n",
      "Original: Hola, confirmo mi asistencia\n",
      "English: Hello, I confirm my attendance\n",
      "Augmented Text: Hello, I confirm my participation\n",
      "To spanish version: Hola confirmo mi participación \n",
      "\n",
      "Original: si, confirmo\n",
      "English: yes, I confirm\n",
      "Augmented Text: Yes, I confirm\n",
      "To spanish version: si, lo confirmo \n",
      "\n",
      "Original: Si, asistiré a la fecha estipulada\n",
      "English: Yes, I will attend the stipulated date\n",
      "Augmented Text: Yes, I will attend the appointment\n",
      "To spanish version: Sí, asistiré a la cita. \n",
      "\n",
      "Original: Si\n",
      "English: And\n",
      "Augmented Text: \n",
      "To spanish version:  \n",
      "\n",
      "Original: Ok\n",
      "English: Ok\n",
      "Augmented Text: \n",
      "To spanish version:  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In this case, we only can use the synonm augmenter\n",
    "# Substite by w2v glove or fasttext\n",
    "augmented_text_fb = aug_fb.augment(augmented_sentences)\n",
    "augmented_text_wn = aug_wordnet.augment(augmented_sentences)\n",
    "translates_fb = en_to_sp(augmented_text_fb)\n",
    "translates_wn = en_to_sp(augmented_text_wn)\n",
    "\n",
    "print('######################Casos WORDNET######################')\n",
    "for i in range(len(augmented_text_fb[:5])):\n",
    "    print(f\"Original: {original[i]}\")\n",
    "    print(f\"English: {augmented_sentences[i]}\")\n",
    "    print(f\"Augmented Text: {augmented_text_wn[i]}\")\n",
    "    print(f\"To spanish version: {translates_wn[i]} \\n\")\n",
    "\n",
    "print('######################Casos Facebook######################')\n",
    "for i in range(len(augmented_text_fb[:5])):\n",
    "    print(f\"Original: {original[i]}\")\n",
    "    print(f\"English: {augmented_sentences[i]}\")\n",
    "    print(f\"Augmented Text: {augmented_text_fb[i]}\")\n",
    "    print(f\"To spanish version: {translates_fb[i]} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
